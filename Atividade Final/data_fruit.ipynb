{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sulShD5y4K7V"
      },
      "source": [
        "# Treinamento com interface de alto nível"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mALEfpx54K7d"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40QD8NA_jquO"
      },
      "outputs": [],
      "source": [
        "!pip install openpyxl scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOn4IXXnGRBg"
      },
      "outputs": [],
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN69WSbu4K7f"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Importando bibliotecas para leitura do dataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqV6Z8ev7coO"
      },
      "source": [
        "### Dataset escolhido\n",
        "https://www.kaggle.com/datasets/muratkokludataset/date-fruit-datasets/data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baixar do Kaggle"
      ],
      "metadata": {
        "id": "NmIKN4C39U5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionei essa sessão aqui caso você queira baixar direto do Kaggle, mas para isso precisa criar um token etc. Se quiser explorar essa opção, veja esse [tutorial](https://www.freecodecamp.org/news/how-to-download-kaggle-dataset-to-google-colab/).\n",
        "\n",
        "Se não quiser fazer assim, pode ignorar e ir direto para a forma que fez usando o Drive"
      ],
      "metadata": {
        "id": "-EPW5ny1IAYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "QcozYfhL8LDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZcTeHUCA9Znz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/Kaggle/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "BDtb9__a9dxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle\n",
        "kaggle.api.authenticate()\n",
        "kaggle.api.dataset_download_files('muratkokludataset/date-fruit-datasets', path='/content/')"
      ],
      "metadata": {
        "id": "fc8zRLl88RG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip date-fruit-datasets.zip"
      ],
      "metadata": {
        "id": "x55pidEo-akw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/Date_Fruit_Datasets/Date_Fruit_Datasets.xlsx'"
      ],
      "metadata": {
        "id": "ljRoxE8W-nSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset do Drive"
      ],
      "metadata": {
        "id": "4HzIo3QT-Rji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RKLV7Ygk9Kx"
      },
      "outputs": [],
      "source": [
        "# conectando com o google drive e adicionando o path para o dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/Dataset/Date_Fruit_Datasets.xlsx'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Montando DF"
      ],
      "metadata": {
        "id": "PMc7EOiM-V91"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgAzu1bslu_e"
      },
      "outputs": [],
      "source": [
        "# Leitura do dataset\n",
        "df = pd.read_excel(file_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CuH_O5qiEk1"
      },
      "outputs": [],
      "source": [
        "def encode (df):\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object' or df[col].dtype == 'category':\n",
        "            le = LabelEncoder()\n",
        "            df[col] = le.fit_transform(df[col])\n",
        "    return df\n",
        "df = encode(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cfoq9DSBLIjf"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75-ROCT_ijYw"
      },
      "outputs": [],
      "source": [
        "# Separando X e Y\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importante\n",
        "Eu adicionei aqui um StandardScaler, o que isso faz é padronizar os dados, ou seja, fazer a normalização deles.\n",
        "\n",
        "Você deve ter percebido que os valores das colunas variam bastante, e como vimos nas aulas anteriores, temos que normalizar os dados para que o modelo consiga fazer o treinamento de maneira adequada. A normalização pode ser feita de muitas formas, como demonstrei em aula, e usando o StardardScaler é uma delas, similar ao MinMax. Leia essa referência que encontrei para relembrar [link](https://medium.com/@mhvasconcelos/distribui%C3%A7%C3%A3o-normal-e-a-biblioteca-standard-scaler-em-python-f21c52070c6b).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Recomendo que tente fazer o treinamento com e sem o StandardScaler e veja a diferença que dá no treinamento. Faça isso e escreva um parágrafo no final do notebook explicando o que aconteceu.**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Para não usar o StandardScaler, basta não executar o trecho de código abaixo"
      ],
      "metadata": {
        "id": "PyAZxzdAI0tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = StandardScaler().fit_transform(X)\n",
        "X[:5]"
      ],
      "metadata": {
        "id": "fsB9MWo8CA6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPldiUqFG2Li"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U84AkCUIRqc"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pegando o shape da entrada para saber como montar a primeira camada da rede\n",
        "# como temos 34 colunas, isso vai refletir na primeira camada\n",
        "X_train_tensor.shape"
      ],
      "metadata": {
        "id": "ab0MsLqqEKlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9a5CrAAOlIy"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSNk1xxHO47M"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T8iS1Jc4K7q"
      },
      "source": [
        "## Criação da rede"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Não recomendo usar rede convolucional pois não estudamos isso a fundo, por conta disso, troquei por uma rede neural tradicional densa.\n",
        "\n",
        "Você deve perceber que a primeira camada, **fc1**, tem como entrada 34 colunas, que são o número de colunas que tem o X do dataset.\n",
        "\n",
        "Adicionalmente, a última camada, **fc4**, tem como saída 7 possibilidades, que são o número de possíveis classes de saída.\n",
        "\n",
        "Basicamente são esses os parâmetros que precisam bater com o dataset, os outros valores da rede podem ser mudados.\n",
        "\n",
        "``` python\n",
        "self.fc1 = nn.Linear(34, 256)\n",
        "...\n",
        "self.fc4 = nn.Linear(64, 7)\n",
        "```\n",
        "\n",
        "A rede que coloquei é exemplo, se quiser, pode deixar ela mais ou menos complexa adicionando ou removendo camadas e neurõnios.\n",
        "\n"
      ],
      "metadata": {
        "id": "1N9YopU7Gchk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUi00oew4K7q"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(34, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "model = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "GxTrp8lN_KfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model(X_train_tensor)"
      ],
      "metadata": {
        "id": "GBJzp7XR_JxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "400Lbat24K7v"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cqllMDO4K7y"
      },
      "source": [
        "### Criando o objeto de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAEOQoZy4K72"
      },
      "outputs": [],
      "source": [
        "def train(log_interval, dry_run, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            if dry_run:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE6DjiKK4K76"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxdm4FTK4K8E"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgH7e25qb_-K"
      },
      "outputs": [],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(1111)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': 64}\n",
        "test_kwargs = {'batch_size': 64}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=1)\n",
        "\n",
        "epochs = 14\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(10, False, model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), \"date_fruit_cnn.pt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "5fe3e6f0cdaab8afdc61c52912fda83f7c0a71baaea1897dd7498e2df01e69ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}